{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "    \n",
    "#read both data sets\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = train_data[['Prediction','Id',\"NextId\",\"Position\"]]\n",
    "test_info = test_data[['Id',\"NextId\",\"Position\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['Prediction','Id',\"NextId\",\"Position\"],axis=1).as_matrix()\n",
    "X_test = test_data.drop(['Prediction','Id',\"NextId\",\"Position\"],axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words=set()\n",
    "str=\"\"\n",
    "for index, row in train_data.iterrows():\n",
    "    str += row[\"Prediction\"]\n",
    "    if row[\"NextId\"] == -1:\n",
    "        unique_words.add(str)\n",
    "        str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_list = list(unique_words)\n",
    "unique_words_list = sorted(unique_words_list, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_map = {}\n",
    "for word in unique_words_list:\n",
    "    words_map[word] = keras.utils.to_categorical(len(words_map) +1, 56).reshape(1,56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_words(info, data, train):\n",
    "    words = np.empty((0, 16,112), int)\n",
    "    predictions = np.empty((0, 56), int)\n",
    "    word_length = np.empty((0, 1), int)\n",
    "    \n",
    "    for index, row in info.iterrows():\n",
    "        if(row[\"Position\"] == 1):\n",
    "            word = data[index].reshape(1,16,8)\n",
    "            if(train):\n",
    "                str = row[\"Prediction\"]\n",
    "        elif(row[\"NextId\"] == -1):\n",
    "            word_length = np.append(word_length, row[\"Position\"])\n",
    "            word = np.append(word, data[index].reshape(1,16,8), axis=2)\n",
    "            if(train):\n",
    "                str += row[\"Prediction\"]\n",
    "                \n",
    "            length = word[0][0].size\n",
    "            while (length < 112):\n",
    "                word = np.append(word, np.full((1,16, 8), 0), axis=2)\n",
    "                length = word[0][0].size\n",
    "                \n",
    "            words =np.append(words, word, axis=0)\n",
    "            if(train):\n",
    "                predictions =np.append(predictions, words_map[str], axis=0)\n",
    "        else:\n",
    "            word = np.append(word, data[index].reshape(1,16,8), axis=2)\n",
    "            if(train):\n",
    "                str += row[\"Prediction\"]\n",
    "    \n",
    "    return words, word_length, predictions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words, test_word_length = create_words(test_info, X_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, train_word_length, predictions = create_words(train_info, X_train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5487, 16, 112) (5487, 56) (5487,)\n"
     ]
    }
   ],
   "source": [
    "print(train_words.shape, predictions.shape, train_word_length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1390, 16, 112) (1390,)\n"
     ]
    }
   ],
   "source": [
    "print(test_words.shape, test_word_length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(1, 16, 112), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(224, activation='relu'))\n",
    "    model.add(Dense(56, activation='softmax'))\n",
    "    sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5487/5487 [==============================] - 151s 28ms/step - loss: 3.1989 - acc: 0.1637\n",
      "Epoch 2/10\n",
      "5487/5487 [==============================] - 151s 28ms/step - loss: 0.6688 - acc: 0.7862\n",
      "Epoch 3/10\n",
      "5487/5487 [==============================] - 150s 27ms/step - loss: 0.2973 - acc: 0.9050\n",
      "Epoch 4/10\n",
      "5487/5487 [==============================] - 153s 28ms/step - loss: 0.2077 - acc: 0.9322\n",
      "Epoch 5/10\n",
      "5487/5487 [==============================] - 153s 28ms/step - loss: 0.1371 - acc: 0.9526\n",
      "Epoch 6/10\n",
      "5487/5487 [==============================] - 154s 28ms/step - loss: 0.1161 - acc: 0.9608\n",
      "Epoch 7/10\n",
      "5487/5487 [==============================] - 154s 28ms/step - loss: 0.0949 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "5487/5487 [==============================] - 154s 28ms/step - loss: 0.0825 - acc: 0.9723\n",
      "Epoch 9/10\n",
      "5487/5487 [==============================] - 155s 28ms/step - loss: 0.0762 - acc: 0.9739\n",
      "Epoch 10/10\n",
      "5487/5487 [==============================] - 154s 28ms/step - loss: 0.0664 - acc: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9cb107470>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(train_words.reshape(5487,1, 16, 112) , predictions, epochs=10, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5487/5487 [==============================] - 150s 27ms/step - loss: 0.0375 - acc: 0.9863\n",
      "Epoch 2/2\n",
      "5487/5487 [==============================] - 149s 27ms/step - loss: 0.0378 - acc: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9c833e518>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_words.reshape(5487,1, 16, 112) , predictions, epochs=2, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_words.reshape(1390,1, 16, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [unique_words_list[np.argmax(p)-1] for p in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(classes)):\n",
    "    if(len(classes[i]) != test_word_length[i]):\n",
    "        print(\"Not matching\", classes[i], test_word_length[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty((0, 1))\n",
    "for i in range(0, len(classes)):\n",
    "    results = np.append(results, list(classes[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10584"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"final_results.csv\", np.dstack((np.arange(0, results.size),results))[0],\"%s,%s\",header=\"Id,Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='final_results.csv' target='_blank'>final_results.csv</a><br>"
      ],
      "text/plain": [
       "/home/user/Projects/PredictionComp1/final_results.csv"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "csv_fn='final_results.csv'\n",
    "FileLink(csv_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
